{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train_Bert.ipynb","provenance":[{"file_id":"155S_bb3viIoL0wAwkIyr1r8XQu4ARwA9","timestamp":1625184350824}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"C3Lzpgo-uoby"},"source":["#Prueba con el .py"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGkl3UlyZhkp","executionInfo":{"status":"ok","timestamp":1626991725081,"user_tz":180,"elapsed":24051,"user":{"displayName":"Gaston R Araujo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpk0N2tOt7GtH1AKLYsp_CVZY30_fwLLYDBIL3=s64","userId":"07348345579296320635"}},"outputId":"902e1314-b3a6-4653-ddd6-d5e95b6c8537"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3RQltoWeCya","executionInfo":{"status":"ok","timestamp":1626991725083,"user_tz":180,"elapsed":10,"user":{"displayName":"Gaston R Araujo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpk0N2tOt7GtH1AKLYsp_CVZY30_fwLLYDBIL3=s64","userId":"07348345579296320635"}},"outputId":"cc4cbf21-c236-4750-8a01-bf3fff2b8342"},"source":["!pwd\n","%cd /content/drive/MyDrive/Proyecto Final Di Paola-Araujo\n","#!pwd\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n","/content/drive/MyDrive/Proyecto Final Di Paola-Araujo\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Da2iVXCDiJrv","executionInfo":{"status":"ok","timestamp":1626991873976,"user_tz":180,"elapsed":148899,"user":{"displayName":"Gaston R Araujo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjpk0N2tOt7GtH1AKLYsp_CVZY30_fwLLYDBIL3=s64","userId":"07348345579296320635"}},"outputId":"1793c690-4cd9-4cab-e4ab-4e3357155470"},"source":["!pip install -q pip==20.3.1\n","# !pip install python==3.6.8\n","!pip install -q torch==1.7.1\n","!pip install -q tqdm==4.49.0\n","!pip install -q transformers==4.2.2\n","!pip install -q tensorboardX"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.5 MB 8.2 MB/s \n","\u001b[K     |████████████████████████████████| 776.8 MB 16 kB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 69 kB 4.7 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 1.8 MB 6.8 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 39.7 MB/s \n","\u001b[K     |████████████████████████████████| 2.9 MB 53.0 MB/s \n","\u001b[K     |████████████████████████████████| 124 kB 9.4 MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GeN0ijRt2gfR","outputId":"94885b46-6182-4ab8-a985-44d6d3be355e"},"source":["!python train.py --do-train --eval-every 758 --run-name Mejora_model_mati\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: 100% 442/442 [00:00<00:00, 439kB/s]\n","Downloading: 100% 268M/268M [00:04<00:00, 57.9MB/s]\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading: 100% 232k/232k [00:00<00:00, 1.82MB/s]\n","Downloading:  36% 168k/466k [00:00<00:00, 1.64MB/s]"],"name":"stdout"}]}]}